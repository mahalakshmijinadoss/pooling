{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "goldbecktwtrobertabase.ipynb",
      "provenance": [],
      "mount_file_id": "138OMIz2DAmLQy7lTjyKbhjlXJZ2-q3S-",
      "authorship_tag": "ABX9TyN/yIUf1gGdMTez3e6la3j6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fddac3cbcfa34861a5dcd08d9c5caea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_30e81a39cdd741a097a7464e3ca945a6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dcbc2f07d0aa4c51a2754a2c94f52430",
              "IPY_MODEL_5df24f02cb434d3ba3f6e9c5b56aac54",
              "IPY_MODEL_0413ff08cef64e69b697d8559c19dea5"
            ]
          }
        },
        "30e81a39cdd741a097a7464e3ca945a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcbc2f07d0aa4c51a2754a2c94f52430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d5613451edc54923b610d074c04fa8e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Upload file pytorch_model.bin: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d2d92d19e4b4e77ba39dcacf7a1b882"
          }
        },
        "5df24f02cb434d3ba3f6e9c5b56aac54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_292266508147403681305d053e4bb703",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 498674093,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 498674093,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4267880ad9fd4b37b9c11a1ce6d2c679"
          }
        },
        "0413ff08cef64e69b697d8559c19dea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d18222b59a049e585ee1ec23fe0f07b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 476M/476M [07:56&lt;00:00, 931kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e719eb8c9f764f9c9c7dcf3a3b9b2c2f"
          }
        },
        "d5613451edc54923b610d074c04fa8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d2d92d19e4b4e77ba39dcacf7a1b882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "292266508147403681305d053e4bb703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4267880ad9fd4b37b9c11a1ce6d2c679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d18222b59a049e585ee1ec23fe0f07b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e719eb8c9f764f9c9c7dcf3a3b9b2c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahalakshmijinadoss/pooling/blob/main/goldbecktwtrobertabase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnyEPLZahKnK"
      },
      "outputs": [],
      "source": [
        "!pip install transformers[sentencepiece]==4.10.0 datasets --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.clear_cache"
      ],
      "metadata": {
        "id": "wY2jJZqXu052"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c  \"import transformers;print(transformers.__version__)\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz4GyJ8VhPAg",
        "outputId": "3e6bcae3-9dfd-4497-947e-30661b47596b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYr9XHDYhTKy",
        "outputId": "fe6e0c73-2985-43e2-e888-b4df25586807"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 200 µs (started: 2022-02-10 03:44:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUTGnCf5l109",
        "outputId": "b9589640-bcf8-487c-ecdf-a061ecf0520d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.44 s (started: 2022-02-10 03:44:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from transformers.file_utils import is_tf_available, is_torch_available, is_torch_tpu_available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeIeWOnMhT8I",
        "outputId": "45568abf-f920-4cf5-bb01-1adae3986b1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 346 ms (started: 2022-02-10 03:45:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed: int):\n",
        "    \"\"\"\n",
        "    Helper function for reproducible behavior to set the seed in ``random``, ``numpy``, ``torch`` and/or ``tf`` (if\n",
        "    installed).\n",
        "\n",
        "    Args:\n",
        "        seed (:obj:`int`): The seed to set.\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if is_torch_available():\n",
        "        torch.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        # ^^ safe to call this function even if cuda is not available\n",
        "    if is_tf_available():\n",
        "        import tensorflow as tf\n",
        "\n",
        "        tf.random.set_seed(seed)\n",
        "\n",
        "set_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCU4HaVHhYHu",
        "outputId": "56ee9c52-918a-4c77-f8f6-d3ad8503b9a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.58 s (started: 2022-02-10 03:45:03 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5py3GSi0hanI",
        "outputId": "e8ef9be7-14fe-4440-af31-68a8bced0c55"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.52 ms (started: 2022-02-10 03:45:13 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1p348_nhpxE",
        "outputId": "c1a986bf-17aa-41ff-8ef5-e1b23a5bbe11"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 130 ms (started: 2022-02-10 03:45:15 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_pViQVDh4gO",
        "outputId": "c23a8550-b19b-4916-d137-436dca1e1a42"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/token.\n",
            "        (Deprecated, will be removed in v0.3.0) To login with username and password instead, interrupt with Ctrl+C.\n",
            "        \n",
            "Token: \n",
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
            "\n",
            "git config --global credential.helper store\u001b[0m\n",
            "time: 11.6 s (started: 2022-02-10 03:45:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "MODEL = \"cardiffnlp/twitter-roberta-base-sep2021\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
      ],
      "metadata": {
        "id": "zl3chzW9h93R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fb22c57-a56d-4385-d749-37c0da7adb0b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sep2021 were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sep2021 and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.05 s (started: 2022-02-10 03:53:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv('/content/goldbeck.csv',sep=',')"
      ],
      "metadata": {
        "id": "apfg59x5iAwC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67c20c5-ed4b-4c47-e141-59addbcc6646"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 87.9 ms (started: 2022-02-10 03:45:57 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NQ18gnw-GUh",
        "outputId": "dfb3b970-1be6-4923-b705-19fd006b7b36"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20360, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 14 ms (started: 2022-02-10 03:46:03 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "5DrpnSj0njTe",
        "outputId": "ce20c956-d43b-4639-95a7-ec881c280649"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ac79fcaf-a485-413a-b773-923fbe0a824e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>@Grumpy_P_Sloth @deanesmay feminists argue for...</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1948Army of England helped the Jews to occupy ...</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Dutch Leader Says Europe to collapse In 6 Week...</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>RT @__DeLay: The next day the Romans and the J...</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>RT @Bakersman_Joe: When Hitler Invited The Jew...</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac79fcaf-a485-413a-b773-923fbe0a824e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac79fcaf-a485-413a-b773-923fbe0a824e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac79fcaf-a485-413a-b773-923fbe0a824e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  ID                                              Tweet label\n",
              "0           0   1  @Grumpy_P_Sloth @deanesmay feminists argue for...     H\n",
              "1           1   2  1948Army of England helped the Jews to occupy ...     H\n",
              "2           2   3  Dutch Leader Says Europe to collapse In 6 Week...     H\n",
              "3           3   4  RT @__DeLay: The next day the Romans and the J...     H\n",
              "4           4   5  RT @Bakersman_Joe: When Hitler Invited The Jew...     H"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 37.5 ms (started: 2022-02-10 03:46:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vprv6TO5xrDl",
        "outputId": "73e8b85b-e803-407f-d34d-a7b4004c45d1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "N    15075\n",
              "H     5285\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 15.6 ms (started: 2022-02-10 03:56:57 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[(df.label == 'H'), 'label'] = 1\n",
        "df.loc[(df.label == 'N'), 'label'] = 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPMjlSqSxlL9",
        "outputId": "a5580aa0-b703-4c0c-e8d3-c0bccb0c3593"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 13.1 ms (started: 2022-02-10 03:57:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=df.Tweet.values\n",
        "y=df.label.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6WxeLJwvWDr",
        "outputId": "f35229de-2287-412b-9fa7-148a080a819d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.31 ms (started: 2022-02-10 03:57:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4eFzPUMvk6E",
        "outputId": "6f363851-ddd0-4414-af9a-f46f813a0242"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 11.7 ms (started: 2022-02-10 03:57:24 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.1, random_state=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjcOSbs1uZYw",
        "outputId": "3b0ba61d-36d8-4c19-e0e0-e9d50ef10f1e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 18.3 ms (started: 2022-02-10 03:57:25 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4ln_9aUuSz9",
        "outputId": "e5ade618-6311-43c1-c7b2-05d48dc308ba"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.89 ms (started: 2022-02-10 03:57:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    new_text = []\n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfPul_2bpOQM",
        "outputId": "2b125ce7-34f0-4cc1-f571-3876d2574890"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.2 ms (started: 2022-02-10 03:57:29 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts= np.array([preprocess(text) for text in X_train])\n",
        "dev_texts= np.array([preprocess(text) for text in X_dev])\n",
        "num_labels=2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2wJtI9otfoM",
        "outputId": "a200fcd9-e7e6-4463-b7d3-77520359e97e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 353 ms (started: 2022-02-10 03:57:31 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts=train_texts.tolist()\n",
        "dev_texts=dev_texts.tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1qqMnolQtZw",
        "outputId": "7902d108-7e93-4ddb-da69-62e09b1dc442"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 68.8 ms (started: 2022-02-10 03:57:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts[0:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c8yp3y75JwV",
        "outputId": "193d7684-8c3e-4d4f-8d13-f893602911cf"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"RT @user Men who want to impress other men rape women - way to go fellas  Australia Navy cadet filmed rape 'to be accepted' http\",\n",
              " 'That would explain why the \\\\\"nice\\\\\" feminists won\\'t tell the radfems to STFU. http',\n",
              " \"The Jews don't like Farrakhan, so they call me Hitler. Well, that's a good name. Hitler was a very great man.\",\n",
              " \"The New Yorker: #Republicans' #Frankenstein #Monster. #Capitalism #Plutocracy #WhitePower #Fascism  http / /t.co /TG6oKS6ATS\",\n",
              " 'Who led the Jews across the semi permeable membrane?   Osmoses',\n",
              " '@user #RespectTheWhiteShoes  #whitepower',\n",
              " 'RT @user Are you guys against all indigenous peoples self determination on their ancestral lands or just the jews? #AskHamas',\n",
              " '@user @user but there is no evidence to prove #gamergate did it',\n",
              " \"Ben Howe's conservatism: feminist, PC, pro-Islam, open borders, and a shill for big business.  http\",\n",
              " \"@user Given that logic, I'm sure the Jews felt very empowered in 1942.\",\n",
              " \"Following this logic, I should be terrified of women due to my past. But fuck that shit because that's dumb. http\",\n",
              " '#GamerGate - To everyone, on both sides: Grow the fuck up. Go outside, see the world, quit stalking &amp; threatening annoying feminists.',\n",
              " 'Liberals, ever the hypocrites, support the worst form of #Apartheid. #PJNet #TCOT #WhiteGenocide #UKIP #2A http / /t.co /bSx0sWYZuY',\n",
              " 'RT @user FORCED immigration + intergration + assimilation in ALL &amp; ONLY White countries is genocide per UN resolution 260 #WhiteGenoc',\n",
              " \"@user @user no thank you, i don't need your links to your bullshit, everyone knows links were created by the jews\",\n",
              " \"RT @user #promocave Book News Update: BOOK REVIEW: 'Lincoln and the Jews: A History' http / /t.co /bBoGJOGOIW #books\",\n",
              " 'RT @user still stuntin on my ex bitch',\n",
              " \"RT @user Never stop improving. Life entropy is real. You're either getting better or getting worse. There is no coasting.\",\n",
              " 'RT @user Listen up cameron your playing with people`s live`s syria not our fucking problem share this http',\n",
              " 'Anti-Judaism is an attitude that sees the Jews to blame &amp; is concerned with imaginary Jews as opposed to real Jews. http / /t.co /Xr5JfjCykJ']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.35 ms (started: 2022-02-10 03:57:35 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_texts,truncation=True,)\n",
        "dev_encodings = tokenizer(dev_texts,truncation=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slj1XFSODKSv",
        "outputId": "0c6730bf-0785-42c1-99d7-ff02d20b90a1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.98 s (started: 2022-02-10 03:57:38 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class TaskDatasetB(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self,encodings,labels):\n",
        "    self.encodings = encodings\n",
        "    self.labels = labels\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    item = {key: torch.tensor(val[idx]) for key,val in self.encodings.items()}\n",
        "    item['labels'] = torch.tensor(self.labels[idx])\n",
        "    return item\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRvVCWTbDMnb",
        "outputId": "64968adc-c011-4e6c-fe58-f3bb141dcba7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 11.3 ms (started: 2022-02-10 03:57:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TaskDatasetB(train_encodings,y_train)\n",
        "dev_dataset = TaskDatasetB(dev_encodings,y_dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r1oAyXYDTKs",
        "outputId": "6e88c995-5c74-4134-9257-8cf190d8ea44"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.74 ms (started: 2022-02-10 03:57:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnYpYx3yDWWO",
        "outputId": "5c1b4bb9-3b0e-4cf2-cf44-42b185a2a3b5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.7 ms (started: 2022-02-10 03:57:45 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    'OGBV-gender-twtrobertabase-en-goldebeck',\n",
        "    run_name = \"twt-roberta-en-3epoch\",\n",
        "    evaluation_strategy = 'epoch',\n",
        "    save_strategy='epoch',\n",
        "    num_train_epochs = 3,\n",
        "    load_best_model_at_end = True,\n",
        "    push_to_hub='OGBV-gender-twtrobertabase-en-goldbeck'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYc1a44kDaLY",
        "outputId": "48da89a8-cca7-4895-deba-406a1eaf001a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 16.5 ms (started: 2022-02-10 03:57:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "\n",
        "  logits,labels = eval_preds\n",
        "  predictions  = np.argmax(logits,axis=-1)\n",
        "\n",
        "  acc = accuracy_score(labels,predictions)\n",
        "  precision = precision_score(labels,predictions,average='weighted')\n",
        "  recall = recall_score(labels,predictions,average='weighted')\n",
        "  f1 = f1_score(labels,predictions,average='weighted')\n",
        "  \n",
        "  return {\n",
        "     'acc' : acc,\n",
        "     'precision' : precision,\n",
        "     'recall' : recall,\n",
        "     'f1' : f1\n",
        "  }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAN5uVqTDgzO",
        "outputId": "da03ed75-05e9-4634-d3b8-dbe4e619f869"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.8 ms (started: 2022-02-10 03:57:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0YGJ-lbwzog",
        "outputId": "ca015a5d-e26f-4d43-858d-dd1cdc3d720e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.41 ms (started: 2022-02-10 03:52:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git-lfs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5uRI8BKDi_I",
        "outputId": "a8275859-b11c-42b3-c265-9b9585ca184a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "time: 2.08 s (started: 2022-02-10 03:53:04 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = dev_dataset,\n",
        "\n",
        "    data_collator = data_collator,\n",
        "    compute_metrics = compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3DELw-GDjjd",
        "outputId": "46f940af-ef09-4ae3-b87b-7c9482a7347b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/huggingface_hub/hf_api.py:1004: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
            "  FutureWarning,\n",
            "/content/OGBV-gender-twtrobertabase-en-goldebeck is already a clone of https://huggingface.co/Maha/OGBV-gender-twtrobertabase-en-goldebeck. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.77 s (started: 2022-02-10 03:57:56 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "6izJd1eUDlLT",
        "outputId": "1729d21a-993f-4d0f-f1d2-e1a88d18a26a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 18324\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 6873\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6873' max='6873' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6873/6873 28:15, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Acc</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.595300</td>\n",
              "      <td>0.597468</td>\n",
              "      <td>0.732809</td>\n",
              "      <td>0.537010</td>\n",
              "      <td>0.732809</td>\n",
              "      <td>0.619814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.573300</td>\n",
              "      <td>0.567671</td>\n",
              "      <td>0.732809</td>\n",
              "      <td>0.537010</td>\n",
              "      <td>0.732809</td>\n",
              "      <td>0.619814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.550700</td>\n",
              "      <td>0.561251</td>\n",
              "      <td>0.752947</td>\n",
              "      <td>0.756114</td>\n",
              "      <td>0.752947</td>\n",
              "      <td>0.676769</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 2036\n",
            "  Batch size = 8\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to OGBV-gender-twtrobertabase-en-goldebeck/checkpoint-2291\n",
            "Configuration saved in OGBV-gender-twtrobertabase-en-goldebeck/checkpoint-2291/config.json\n",
            "Model weights saved in OGBV-gender-twtrobertabase-en-goldebeck/checkpoint-2291/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2036\n",
            "  Batch size = 8\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to OGBV-gender-twtrobertabase-en-goldebeck/checkpoint-4582\n",
            "Configuration saved in OGBV-gender-twtrobertabase-en-goldebeck/checkpoint-4582/config.json\n",
            "Model weights saved in OGBV-gender-twtrobertabase-en-goldebeck/checkpoint-4582/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2036\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to OGBV-gender-twtrobertabase-en-goldebeck/checkpoint-6873\n",
            "Configuration saved in OGBV-gender-twtrobertabase-en-goldebeck/checkpoint-6873/config.json\n",
            "Model weights saved in OGBV-gender-twtrobertabase-en-goldebeck/checkpoint-6873/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from OGBV-gender-twtrobertabase-en-goldebeck/checkpoint-6873 (score: 0.5612505674362183).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6873, training_loss=0.5689310123527412, metrics={'train_runtime': 1695.4122, 'train_samples_per_second': 32.424, 'train_steps_per_second': 4.054, 'total_flos': 1327148607676800.0, 'train_loss': 0.5689310123527412, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 28min 15s (started: 2022-02-10 03:58:04 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "ZlEIuJzrDo9i",
        "outputId": "f7c45504-7082-455e-a775-fda85cfa60ba"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 2036\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='255' max='255' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [255/255 00:16]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_acc': 0.7529469548133595,\n",
              " 'eval_f1': 0.6767694098208894,\n",
              " 'eval_loss': 0.5612505674362183,\n",
              " 'eval_precision': 0.7561143570253707,\n",
              " 'eval_recall': 0.7529469548133595,\n",
              " 'eval_runtime': 16.3558,\n",
              " 'eval_samples_per_second': 124.481,\n",
              " 'eval_steps_per_second': 15.591}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 16.4 s (started: 2022-02-10 04:26:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exUIeny5e_pZ",
        "outputId": "da18747c-730a-40e7-82c6-1b38438afff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 277 ms (started: 2022-02-09 18:07:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'OGBV-gender-twtrobertabase-en-goldbeck'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcpcSiZLFfWb",
        "outputId": "795cc480-bfdb-4007-e837-676b2e08d323"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.75 ms (started: 2022-02-10 04:26:46 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub('OGBV-gender-twtrobertabase-en-goldbeck')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "fddac3cbcfa34861a5dcd08d9c5caea9",
            "30e81a39cdd741a097a7464e3ca945a6",
            "dcbc2f07d0aa4c51a2754a2c94f52430",
            "5df24f02cb434d3ba3f6e9c5b56aac54",
            "0413ff08cef64e69b697d8559c19dea5",
            "d5613451edc54923b610d074c04fa8e9",
            "5d2d92d19e4b4e77ba39dcacf7a1b882",
            "292266508147403681305d053e4bb703",
            "4267880ad9fd4b37b9c11a1ce6d2c679",
            "1d18222b59a049e585ee1ec23fe0f07b",
            "e719eb8c9f764f9c9c7dcf3a3b9b2c2f"
          ]
        },
        "id": "Lbi5bjxkFiFO",
        "outputId": "b307bfc9-fe46-4e9c-fb49-217628d647bd"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/huggingface_hub/hf_api.py:1004: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
            "  FutureWarning,\n",
            "Cloning https://huggingface.co/Maha/OGBV-gender-twtrobertabase-en-goldbeck into local empty directory.\n",
            "Configuration saved in OGBV-gender-twtrobertabase-en-goldbeck/config.json\n",
            "Model weights saved in OGBV-gender-twtrobertabase-en-goldbeck/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fddac3cbcfa34861a5dcd08d9c5caea9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 3.37k/476M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "To https://huggingface.co/Maha/OGBV-gender-twtrobertabase-en-goldbeck\n",
            "   781a14d..2b35ee3  main -> main\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://huggingface.co/Maha/OGBV-gender-twtrobertabase-en-goldbeck/commit/2b35ee39f5fa838c8ceb5cf0f47e78500e3b800c'"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8min 13s (started: 2022-02-10 04:26:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.push_to_hub('OGBV-gender-twtrobertabase-en-goldbeck')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "NG_JisXdFjw0",
        "outputId": "d68908d0-aea8-4e48-c5f2-5637045e53cb"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizer config file saved in OGBV-gender-twtrobertabase-en-goldbeck/tokenizer_config.json\n",
            "Special tokens file saved in OGBV-gender-twtrobertabase-en-goldbeck/special_tokens_map.json\n",
            "To https://huggingface.co/Maha/OGBV-gender-twtrobertabase-en-goldbeck\n",
            "   2b35ee3..c9ff47d  main -> main\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://huggingface.co/Maha/OGBV-gender-twtrobertabase-en-goldbeck/commit/c9ff47d00892366b5cbc8931c81304a88989f023'"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.09 s (started: 2022-02-10 04:36:07 +00:00)\n"
          ]
        }
      ]
    }
  ]
}